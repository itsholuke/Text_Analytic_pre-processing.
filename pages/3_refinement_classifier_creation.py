# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  streamlit_app.py  â€“  FULL VERSION with tacticâ€‘aware Stepâ€¯4
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re, ast

st.title("ğŸ“Š Marketingâ€‘Tactic Text Classifier")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STEPâ€¯1 â€“ choose tactic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
default_tactics = {
    "urgency_marketing":  ["now", "today", "limited", "hurry", "exclusive"],
    "social_proof":       ["bestseller", "popular", "trending", "recommended"],
    "discount_marketing": ["sale", "discount", "deal", "free", "offer"],
    "Classic_Timeless_Luxury_style": [
        'elegance', 'heritage', 'sophistication', 'refined', 'timeless', 'grace',
        'legacy', 'opulence', 'bespoke', 'tailored', 'understated', 'prestige',
        'quality', 'craftsmanship', 'heirloom', 'classic', 'tradition', 'iconic',
        'enduring', 'rich', 'authentic', 'luxury', 'fine', 'pure', 'exclusive',
        'elite', 'mastery', 'immaculate', 'flawless', 'distinction', 'noble',
        'chic', 'serene', 'clean', 'minimal', 'poised', 'balanced', 'eternal',
        'neutral', 'subtle', 'grand', 'timelessness', 'tasteful', 'quiet', 'sublime'
    ]
}
tactic = st.selectbox("ğŸ¯ Stepâ€¯1 â€” choose a tactic", list(default_tactics.keys()))
st.write(f"Chosen tactic: *{tactic}*")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STEPâ€¯2 â€“ upload CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
file = st.file_uploader("ğŸ“ Stepâ€¯2 â€” upload CSV", type="csv")

# ---------- helper functions --------------------------------
def clean(txt: str) -> str:
    """Lowerâ€‘case & remove punctuation/digits for simple tokenisation."""
    return re.sub(r"[^a-zA-Z0-9\s]", "", str(txt).lower())

def classify(txt: str, dct):
    """Return list of categories whose term list appears at least once."""
    toks = txt.split()
    return [cat for cat, terms in dct.items() if any(w in toks for w in terms)] or ["uncategorized"]
# ------------------------------------------------------------

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit session default flags/objects â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "dict_ready"  not in st.session_state: st.session_state.dict_ready  = False
if "dictionary"  not in st.session_state: st.session_state.dictionary  = {}
if "top_words"   not in st.session_state: st.session_state.top_words   = pd.Series(dtype=int)
if "df"          not in st.session_state: st.session_state.df          = pd.DataFrame()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#                   MAIN APP LOGIC
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if file:
    df = pd.read_csv(file)
    st.dataframe(df.head())

    text_col = st.selectbox("ğŸ“‹ Stepâ€¯3 â€” select text column", df.columns)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STEPâ€¯4 â€“ generate / refine dictionary â”€â”€â”€â”€â”€â”€
    if st.button("ğŸ§  Stepâ€¯4 â€” Generate Keywords & Dictionary"):
        df["cleaned"] = df[text_col].apply(clean)

        # 1. tactic seed terms
        base_terms = set(default_tactics[tactic])

        # 2. rows that mention â‰¥1 base term
        df["row_matches_tactic"] = df["cleaned"].apply(
            lambda x: any(tok in x.split() for tok in base_terms)
        )
        pos_df = df[df["row_matches_tactic"]]

        # 3. contextual term mining inside matching rows
        stop_words = {
            'the', 'is', 'in', 'on', 'and', 'a', 'for', 'you', 'i', 'are', 'of',
            'your', 'to', 'my', 'with', 'it', 'me', 'this', 'that', 'or'
        }

        if pos_df.empty:
            st.warning(
                "None of the rows contained the base terms for this tactic. "
                "Auto dictionary will consist of the default terms only."
            )
            contextual_terms = []
            contextual_freq  = pd.Series(dtype=int)
        else:
            all_pos_words = " ".join(pos_df["cleaned"]).split()
            word_freq = pd.Series(all_pos_words).value_counts()

            contextual_terms = [
                w for w in word_freq.index
                if w not in stop_words and w not in base_terms
            ][:30]                              # topâ€‘30 contextual words
            contextual_freq = word_freq.loc[contextual_terms]

        # 4. merge seed + contextual â†’ dictionary
        auto_dict = {tactic: sorted(base_terms.union(contextual_terms))}

        # 5. show info and allow editing
        st.subheader("Top contextual keywords (filtered)")
        if not contextual_freq.empty:
            st.dataframe(contextual_freq.rename("Frequency"))
        else:
            st.write("â€‘â€‘ none found â€‘â€‘")

        st.write("Autoâ€‘generated dictionary:", auto_dict)

        dict_text = st.text_area(
            "âœ Edit dictionary (Python dict syntax)",
            value=str(auto_dict),
            height=150
        )
        try:
            final_dict = ast.literal_eval(dict_text)
            st.session_state.dictionary = final_dict
            st.success("Dictionary saved.")
        except Exception:
            st.error("Bad format â†’ using auto dict.")
            st.session_state.dictionary = auto_dict

        # 6. persist for Stepâ€¯5
        st.session_state.df         = df
        st.session_state.top_words  = contextual_freq           # Series
        st.session_state.dict_ready = True

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STEPâ€¯5 â€“ run classifier (only if ready) â”€â”€â”€â”€
    if st.session_state.dict_ready:
        if st.button("ğŸ§ª Stepâ€¯5 â€” Run Classification"):
            df         = st.session_state.df.copy()
            top_words  = st.session_state.top_words
            dictionary = st.session_state.dictionary

            df["categories"] = df["cleaned"].apply(lambda x: classify(x, dictionary))
            df["tactic_flag"] = df["categories"].apply(
                lambda cats: 1 if tactic in cats else 0
            )

            counts = pd.Series(
                [c for cats in df["categories"] for c in cats]
            ).value_counts()

            st.subheader("ğŸ“Š Category frequencies")
            st.table(counts)

            st.subheader("ğŸ”‘ Top contextual keywords")
            if not top_words.empty:
                st.table(top_words)
            else:
                st.write("â€‘â€‘ none to display â€‘â€‘")

            fig, ax = plt.subplots(figsize=(10, 4))
            if not top_words.empty:
                top_words.sort_values(ascending=False).plot.bar(ax=ax)
                ax.set_title("Top contextual keyword frequencies")
            else:
                ax.text(0.5, 0.5, "No contextual keywords", ha="center", va="center")
                ax.set_axis_off()
            st.pyplot(fig)

            # downloads
            st.download_button(
                "ğŸ“¥ classified_results.csv",
                df.to_csv(index=False).encode(),
                "classified_results.csv",
                "text/csv",
            )
            st.download_button(
                "ğŸ“¥ category_frequencies.csv",
                counts.to_csv().encode(),
                "category_frequencies.csv",
                "text/csv",
            )
            if not top_words.empty:
                st.download_button(
                    "ğŸ“¥ top_keywords.csv",
                    top_words.to_csv().encode(),
                    "top_keywords.csv",
                    "text/csv",
                )
else:
    st.info("Upload aÂ CSVÂ toÂ begin.")
